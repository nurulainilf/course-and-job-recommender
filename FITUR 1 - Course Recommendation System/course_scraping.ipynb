{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6453bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b6a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.coursera.org/search?query=technology\")\n",
    "time.sleep(2)\n",
    "\n",
    "data = []\n",
    "visited = set()\n",
    "scroll_attempts = 0\n",
    "max_scrolls = 10\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "while scroll_attempts < max_scrolls:\n",
    "    cards = driver.find_elements(By.CSS_SELECTOR, \"li.cds-9.cds-grid-item\")\n",
    "    new_data = []\n",
    "\n",
    "    for card in cards:\n",
    "        try:\n",
    "            title = card.find_element(By.CSS_SELECTOR, \"h3.cds-CommonCard-title\").text.strip()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            institution = card.find_element(By.CSS_SELECTOR, \"p.cds-ProductCard-partnerNames\").text.strip()\n",
    "        except:\n",
    "            institution = \"\"\n",
    "\n",
    "        key = (title, institution)\n",
    "        if key in visited:\n",
    "            continue\n",
    "        visited.add(key)\n",
    "\n",
    "        try:\n",
    "            metadata = card.find_element(By.CSS_SELECTOR, \"div.cds-CommonCard-metadata > p\").text.strip()\n",
    "        except:\n",
    "            metadata = \"\"\n",
    "\n",
    "        try:\n",
    "            rating = card.find_element(By.CSS_SELECTOR, \"span.css-6ecy9b\").text.strip()\n",
    "        except:\n",
    "            rating = \"\"\n",
    "\n",
    "        try:\n",
    "            link = card.find_element(By.CSS_SELECTOR, \"a.cds-CommonCard-titleLink\").get_attribute(\"href\")\n",
    "        except:\n",
    "            link = \"\"\n",
    "\n",
    "        # Check course type\n",
    "        if \"Professional Certificate\" in metadata:\n",
    "            tipe = \"Professional Certificate\"\n",
    "        elif \"Specialization\" in metadata:\n",
    "            tipe = \"Specialization\"\n",
    "        elif \"Course\" in metadata:\n",
    "            tipe = \"Course\"\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Open the detail page\n",
    "        category, subcategory = \"\", \"\"\n",
    "        description, skills = \"\", \"\"\n",
    "        modules = []\n",
    "\n",
    "        try:\n",
    "            r = requests.get(link, headers=headers, timeout=15)\n",
    "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "            # Category & subcategory\n",
    "            breadcrumb_items = soup.select('nav[aria-label=\"Breadcrumbs\"] ol li a')\n",
    "            texts = [item.get_text(strip=True) for item in breadcrumb_items]\n",
    "            category = texts[2] if len(texts) >= 3 else \"\"\n",
    "            subcategory = texts[3] if len(texts) >= 4 else \"\"\n",
    "\n",
    "            # Description\n",
    "            desc_tag = soup.find(\"p\", class_=\"css-4s48ix\")\n",
    "            description = desc_tag.get_text(strip=True) if desc_tag else None\n",
    "\n",
    "            # Skills\n",
    "            skill_items = soup.select(\"ul[class*='css-yk0mzy'] a\")\n",
    "            skills = \", \".join([s.get_text(strip=True) for s in skill_items if s.get_text(strip=True)])\n",
    "\n",
    "            # Modules\n",
    "            number = None\n",
    "            first_block = soup.find(\"div\", class_=\"css-dwgey1\")\n",
    "            if first_block:\n",
    "                link_tag = first_block.find(\"a\")\n",
    "                if link_tag:\n",
    "                    words = link_tag.text.strip().split()\n",
    "                    if words and words[0].isdigit():\n",
    "                        number = int(words[0])\n",
    "\n",
    "            module_names = []\n",
    "            module_descriptions = []\n",
    "            \n",
    "            items = soup.select('[data-testid=\"accordion-item\"]')\n",
    "            for idx, item in enumerate(items):\n",
    "                if number is not None and idx >= number:\n",
    "                    break\n",
    "\n",
    "                judul_el = item.select_one('h3')\n",
    "                judul = judul_el.get_text(strip=True) if judul_el else \"\"\n",
    "                module_names.append(judul)\n",
    "\n",
    "                mod_description = \"\"\n",
    "\n",
    "                if tipe in [\"Specialization\", \"Professional Certificate\"]:\n",
    "                    desc_container = item.select_one('.css-15ekt44')\n",
    "                    if desc_container:\n",
    "                        list_items = desc_container.select('li')\n",
    "                        if list_items:\n",
    "                            mod_description = \"; \".join([li.get_text(strip=True) for li in list_items])\n",
    "                        else:\n",
    "                            para_items = desc_container.select('p')\n",
    "                            mod_description = \" \".join([p.get_text(strip=True) for p in para_items if p.get_text(strip=True)])\n",
    "\n",
    "                elif tipe == \"Course\":\n",
    "                    desc_container = item.select_one('.css-15ekt44')\n",
    "                    if desc_container:\n",
    "                        first_element = desc_container.find(recursive=False)\n",
    "                        if first_element:\n",
    "                            raw_text = first_element.get_text(strip=True)\n",
    "                            mod_description = raw_text.split(\"What's included\")[0].strip()\n",
    "\n",
    "                module_descriptions.append(mod_description)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Gagal scraping detail dari {link}: {e}\")\n",
    "\n",
    "        # Tambahkan ke hasil\n",
    "        new_data.append({\n",
    "            \"Title\": title,\n",
    "            \"Institution\": institution,\n",
    "            \"Metadata\": metadata,\n",
    "            \"Rating\": rating,\n",
    "            \"Link\": link,\n",
    "            \"Category\": category,\n",
    "            \"Subcategory\": subcategory,\n",
    "            \"Description\": description,\n",
    "            \"Skills\": skills,\n",
    "            \"Modules Name\": module_names,\n",
    "            \"Modules Description\": module_descriptions\n",
    "        })\n",
    "\n",
    "    if new_data:\n",
    "        data.extend(new_data)\n",
    "        scroll_attempts = 0\n",
    "    else:\n",
    "        scroll_attempts += 1\n",
    "\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    driver.execute_script(\"window.scrollBy(0, -1500);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"data/courses_data_raw.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
